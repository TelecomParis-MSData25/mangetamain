{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0493f87",
   "metadata": {},
   "source": [
    "# Analyse de la popularité des recettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909f9131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racine détectée: /Users/gregoirepetit/mangetamain\n",
      "Racine projet : /Users/gregoirepetit/mangetamain\n",
      "Téléchargement vers : /Users/gregoirepetit/mangetamain/data\n",
      "Dataset URL: https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions\n",
      "✅ Téléchargement terminé.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "import ipynbname # permet de trouver le chemin du notebook en cours\n",
    "REPO_ROOT = ipynbname.path().parents[2]  # dataset_analysis/popularity -> dataset_analysis -> racine\n",
    "print(\"Racine détectée:\", REPO_ROOT)\n",
    "\n",
    "script_path = REPO_ROOT / \"scripts\" / \"download_data.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"download_data\", script_path)\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(mod)\n",
    "\n",
    "mod.download_and_extract()  # télécharge dans <repo>/data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Import des datasets\n",
    "data_path = REPO_ROOT / \"data\"\n",
    "recipes = pd.read_csv(data_path / \"RAW_recipes.csv\")\n",
    "interactions = pd.read_csv(data_path / \"RAW_interactions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae288496",
   "metadata": {},
   "source": [
    "## Exploration initiale des données\n",
    "\n",
    "Commençons par comprendre la structure des données et identifier les métriques de popularité disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.head() # Afficher les premières lignes du DataFrame des recettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head() # Afficher les premières lignes du DataFrame des interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679a275",
   "metadata": {},
   "source": [
    "- On peut repérer quelques colonnes intéressantes dans les datasets :\n",
    "  - Dans `RAW_recipes.csv` : `id`, `minutes`, `submitted`, `n_steps`, `n_ingredients`, `contributor_id`\n",
    "  - Dans `RAW_interactions.csv` : `user_id`, `recipe_id`, `rating`, `date`, `review`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0be277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On contrôle les valeurs manquantes\n",
    "print(\"Valeurs manquantes dans les recettes par variable: \\n\", recipes.isna().sum(), \"\\n\")\n",
    "print(\"Valeurs manquantes dans les interactions par variable: \\n\", interactions.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On trace des boxplots pour visualiser la distribution de certaines variables numériques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.boxplot(y=recipes['minutes'], ax=axes[0])\n",
    "axes[0].set_title('Temps de préparation (minutes)')\n",
    "axes[0].set_ylabel('minutes')\n",
    "\n",
    "sns.boxplot(y=recipes['n_steps'], ax=axes[1])\n",
    "axes[1].set_title(\"Nombre d'étapes\")\n",
    "axes[1].set_ylabel('n_steps')\n",
    "\n",
    "sns.boxplot(y=recipes['n_ingredients'], ax=axes[2])\n",
    "axes[2].set_title(\"Nombre d'ingrédients\")\n",
    "axes[2].set_ylabel('n_ingredients')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b2025",
   "metadata": {},
   "source": [
    "- Les distributions du temps de préparation (`minutes`), du nombre d'étapes (`n_steps`) et du nombre d'ingrédients (`n_ingredients`) sont toutes très asymétriques, avec une majorité de recettes ayant des valeurs faibles et quelques recettes extrêmes tirant les distributions vers le haut.\n",
    "- On observe la présence de nombreux outliers, en particulier pour le temps de préparation, ce qui indique que certaines recettes demandent beaucoup plus de temps que la moyenne.\n",
    "- La plupart des recettes nécessitent un nombre modéré d'étapes et d'ingrédients, mais il existe des recettes très complexes avec de nombreux ingrédients ou étapes.\n",
    "- Ces variables présentent donc une forte hétérogénéité, ce qui devra être pris en compte dans l’analyse de la popularité des recettes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dda746",
   "metadata": {},
   "source": [
    "### Traitement : 'minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la recette avec le temps de préparation minimum\n",
    "print(\"Recette avec le temps de préparation minimum :\")\n",
    "recipes.loc[[recipes['minutes'].idxmin()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06333c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la recette avec le temps de préparation maximum\n",
    "print(\"Recette avec le temps de préparation maximum :\")\n",
    "recipes.loc[[recipes['minutes'].idxmax()]]  # Double brackets = DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a9df6",
   "metadata": {},
   "source": [
    "- On constate un temps anormalement grand pour le temps de préparation maximum&nbsp;:\n",
    "  \n",
    "  > 2&nbsp;147&nbsp;483&nbsp;647 minutes  \n",
    "  > soit environ `4085.8 ans` (`2147483647 / (60 × 24 × 365)`), ce qui est clairement une erreur ou une valeur aberrante.\n",
    "\n",
    "- Nous faisons le choix de retirer cette valeur extrême de notre analyse pour éviter qu'elle n'influence les résultats.\n",
    "- On remarque également que certaines recettes ont un temps de préparation de 0 minutes, ce qui est probablement une erreur ou une valeur manquante mal codée. Nous allons les traiter en les remplaçant par des valeurs NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4dcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer la recette avec le temps de préparation maximum (valeur aberrante)\n",
    "recipes = recipes[recipes['minutes'] != recipes['minutes'].max()]\n",
    "\n",
    "# Indiquer NA pour celles qui ont 0 minutes\n",
    "recipes.loc[recipes['minutes'] == 0, 'minutes'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe64e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau boxplot pour constater la distribution après le traitement\n",
    "sns.boxplot(x = 'minutes', data = recipes)\n",
    "plt.title(\"Boxplot du temps de préparation (minutes)\")\n",
    "plt.xlabel(\"minutes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9392f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche les 5 recettes avec le plus grand temps de préparation (minutes)\n",
    "recipes.sort_values('minutes', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3a71",
   "metadata": {},
   "source": [
    "- La recette \"how to preserve a husband\" semble être une plaisanterie ou une erreur de saisie plutôt qu'une vraie recette, son temps de préparation étant aussi significativement au-dessus des autres sans élément concret pour le justifier. \n",
    "  - Nous ferons le choix de la retirer pour la suite de l'analyse.\n",
    "- Il semblerait que que le reste des recettes correspondent à des fermentations, d'où leur durée très grande.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire la recette \"how to preserve a husband\"\n",
    "recipes = recipes[recipes['minutes'] != recipes['minutes'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87657f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculs des statistiques descriptives de la colonne 'minutes'\n",
    "stats_minutes = recipes['minutes'].describe()\n",
    "stats_minutes['variance'] = recipes['minutes'].var()\n",
    "stats_minutes['skewness'] = recipes['minutes'].skew()\n",
    "stats_minutes['kurtosis'] = recipes['minutes'].kurtosis()\n",
    "stats_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9f008",
   "metadata": {},
   "source": [
    "- Les statistiques descriptives de la colonne `minutes` montrent une forte asymétrie :\n",
    "    - La médiane (50%) est de 40 minutes, alors que la moyenne est beaucoup plus élevée (~123,7 minutes), ce qui indique la présence de valeurs extrêmes tirant la moyenne vers le haut.\n",
    "    - L'écart-type est très grand (1982 minutes), bien supérieur à la médiane, ce qui confirme la dispersion importante des temps de préparation.\n",
    "    - Le minimum est de 1 minute, le maximum de 288 000 minutes (soit 200 jours), ce qui révèle des valeurs aberrantes ou des recettes très particulières (fermentations, erreurs de saisie).\n",
    "    - Le skewness (asymétrie) et la kurtosis (aplatissement) sont extrêmement élevés, ce qui traduit une distribution très éloignée de la normale, avec de nombreux outliers.\n",
    "\n",
    "- Passer en échelle logarithmique permet de mieux visualiser la distribution des temps de préparation :\n",
    "    - L'échelle linéaire \"écrase\" la majorité des recettes (à faible durée) à cause de quelques valeurs extrêmes.\n",
    "    - L'échelle logarithmique \"compresse\" les grandes valeurs et \"étale\" les petites, rendant la distribution plus lisible et permettant d'observer les tendances pour la majorité des recettes, tout en conservant l'information sur les valeurs élevées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='minutes', data=recipes)\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(\"Boxplot du temps de préparation (minutes) (log)\")\n",
    "ax.set_xlabel(\"minutes (log)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb4e10",
   "metadata": {},
   "source": [
    "- On remarque encore une présence élevée de valeurs extrêmes, malgré l'élimination des recettes aberrantes, l'ajout des NA pour les recettes à 0 et le passage en échelle logarithmique.\n",
    "- Cela suggère que le temps de préparation des recettes est intrinsèquement très variable, avec une majorité de recettes rapides et quelques recettes très longues.\n",
    "- Nous pourrions envisager d'autres transformations ou segmentations pour mieux capturer cette variabilité dans l'analyse de la popularité des recettes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c2d4b",
   "metadata": {},
   "source": [
    "### Traitement : 'n_steps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='n_steps', data=recipes)\n",
    "plt.title(\"Boxplot du nombre d'étapes\")\n",
    "plt.xlabel(\"n_steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96954c72",
   "metadata": {},
   "source": [
    "- Le boxplot du nombre d'étapes (`n_steps`) montre une distribution très asymétrique, avec une majorité de recettes ayant peu d'étapes et une longue \"queue\" de valeurs élevées.\n",
    "- On observe de nombreux outliers au-dessus de la borne supérieure du boxplot, ce qui indique la présence de recettes particulièrement complexes ou de valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['n_steps'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c4c24",
   "metadata": {},
   "source": [
    "- La moyenne de la colonne n_steps étant aux alentours de 10 étapes et le maximum à 145 avec un écart-type de 6, nous pouvons proposer de concaténer le n_steps en catégories :\n",
    "    - Simple (1-5 étapes)\n",
    "    - Modéré (6-10 étapes)\n",
    "    - Complexe (11-20 étapes)\n",
    "    - Très complexe (>20 étapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégorisation simple pour l'analyse\n",
    "def categorize_complexity(n_steps):\n",
    "    if n_steps <= 5: return \"Simple\"\n",
    "    elif n_steps <= 10: return \"Modéré\" \n",
    "    elif n_steps <= 20: return \"Complexe\"\n",
    "    else: return \"Très complexe\"\n",
    "\n",
    "recipes['complexity'] = recipes['n_steps'].apply(categorize_complexity)\n",
    "\n",
    "# Distribution par complexité\n",
    "complexity_dist = recipes['complexity'].value_counts()\n",
    "print(f\"\\n Distribution par complexité:\")\n",
    "for category, count in complexity_dist.items():\n",
    "    pct = count/len(recipes)*100\n",
    "    print(f\"• {category}: {count:,} recettes ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Histogramme avec échelle logarithmique sur l'axe Y (pour voir les queues)\n",
    "sns.histplot(data=recipes, x='n_steps', bins=50, kde=False, ax=ax1, alpha=0.7, color='skyblue')\n",
    "ax1.axvline(recipes['n_steps'].mean(), color='red', linestyle='--', alpha=0.8, label=f'Moyenne: {recipes[\"n_steps\"].mean():.1f}')\n",
    "ax1.axvline(recipes['n_steps'].median(), color='orange', linestyle='--', alpha=0.8, label=f'Médiane: {recipes[\"n_steps\"].median():.0f}')\n",
    "ax1.set_title('Distribution du nombre d\\'étapes (échelle log)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Nombre d\\'étapes')\n",
    "ax1.set_ylabel('Fréquence (log)')\n",
    "ax1.set_yscale('log')  # Échelle logarithmique pour mieux voir les queues\n",
    "ax1.legend()\n",
    "ax1.set_xlim(0, 100)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Boxplot uniquement pour la catégorie \"Très complexe\"\n",
    "sns.boxplot(data=recipes[recipes['complexity'] == \"Très complexe\"], x='complexity', y='n_steps', ax=ax2, palette='viridis')\n",
    "ax2.set_title('Distribution pour \"Très complexe\"', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Niveau de complexité')\n",
    "ax2.set_ylabel('Nombre d\\'étapes')\n",
    "ax2.set_ylim(0, 80)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb10bd",
   "metadata": {},
   "source": [
    "- Utilisation de l'échelle log verticale pour l'histogramme du nombre d'étapes pour mieux visualiser la queue de la distribution et les outliers.\n",
    "- Boxplot uniquement pour la catégorie \"Très complexe\" pour mieux visualiser les statistiques descriptives et la présence d'outliers dans cette catégorie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc28fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes[recipes['n_steps'] >= 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996459b7",
   "metadata": {},
   "source": [
    "- ajout d'un tri avec n_steps >= 40 & minutes >= 1200 (20 heures) pour repérer les recettes les plus longues et complexes, potentiellement des erreurs ou des recettes très particulières (fermentations, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc1afe",
   "metadata": {},
   "source": [
    "### Traitement : 'n_ingredients'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed4f99",
   "metadata": {},
   "source": [
    "## Traitement : Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6957f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4a836",
   "metadata": {},
   "source": [
    "### Traitement : 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb896c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "bins = np.arange(0, 6, 1)  # De 0 à 5 par pas de 1\n",
    "sns.histplot(interactions['rating'], bins=bins, kde=False, color='skyblue', alpha=0.7)\n",
    "plt.title(\"Distribution des notes (rating) - Échelle logarithmique\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Note\")\n",
    "plt.ylabel(\"Nombre d'interactions (log)\")\n",
    "plt.yscale('log')  # Échelle logarithmique pour mieux voir les détails\n",
    "plt.xticks(range(int(interactions['rating'].min()), int(interactions['rating'].max()) + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd3e39",
   "metadata": {},
   "source": [
    "- on regarde les notes à 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[interactions['rating'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80be9b2",
   "metadata": {},
   "source": [
    "- Il semblerait que les notes à 0 soient simplement des commentaires sans évaluation chiffrée, ou des évaluations non renseignées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du nombre et du pourcentage d'interactions avec rating = 0\n",
    "nb_rating_0 = (interactions['rating'] == 0).sum()\n",
    "pct_rating_0 = nb_rating_0 / len(interactions) * 100\n",
    "print(f\"Nombre d'interactions avec rating = 0 : {nb_rating_0:,} ({pct_rating_0:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf6294",
   "metadata": {},
   "source": [
    "- Nous faisons le choix de les passer à NA pour ne pas biaiser l'analyse des notes réelles (1 à 5).\n",
    "- Elles constituent une part non négligeable des intéractions, ce qui suggère que de nombreux utilisateurs laissent des commentaires sans évaluer la recette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer NA pour les ratings = 0\n",
    "interactions.loc[interactions['rating'] == 0, 'rating'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca9da2",
   "metadata": {},
   "source": [
    "### Traitement : 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les lignes sans commentaire textuel\n",
    "interactions[interactions['review'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du nombre et du pourcentage d'interactions sans commentaire textuel\n",
    "nb_no_review = interactions['review'].isna().sum()\n",
    "pct_no_review = nb_no_review / len(interactions) * 100\n",
    "print(f\"Nombre d'interactions sans commentaire textuel : {nb_no_review:,} ({pct_no_review:.2f}%)\")\n",
    "\n",
    "# Calcul de la note moyenne pour les interactions sans commentaire textuel\n",
    "mean_rating_no_review = interactions.loc[interactions['review'].isna(), 'rating'].mean()\n",
    "print(f\"Note moyenne des interactions sans commentaire textuel : {mean_rating_no_review:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la longueur des commentaires\n",
    "interactions['review_length'] = interactions['review'].str.len()\n",
    "\n",
    "# Statistiques descriptives sur la longueur des reviews\n",
    "interactions['review_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la longueur moyenne des reviews par rating\n",
    "mean_review_length_by_rating = interactions.groupby('rating')['review_length'].mean()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "mean_review_length_by_rating.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Longueur moyenne des reviews par note\")\n",
    "plt.xlabel(\"Note\")\n",
    "plt.ylabel(\"Longueur moyenne du commentaire\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7750b7",
   "metadata": {},
   "source": [
    "## Préparation des données pour l'analyse univariée de la popularité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45694e9",
   "metadata": {},
   "source": [
    "### Agrégations par recette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_metrics = interactions.groupby('recipe_id').agg({\n",
    "    'rating': ['count', 'mean', 'median', 'std'],\n",
    "    'user_id': 'nunique', # Nombre d'utilisateurs uniques ayant noté la recette\n",
    "    'review': lambda x: x.notna().sum() # Nombre de reviews avec texte\n",
    "}).round(3) # Arrondir à 3 décimales\n",
    "\n",
    "# Applatir les colonnes multi-niveaux\n",
    "recipe_metrics.columns = ['n_interactions', 'avg_rating', 'median_rating', 'std_rating', 'n_unique_users', 'n_reviews_text'] # n_ratings --> n_interactions pour plus de clarté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_metrics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb4b3b",
   "metadata": {},
   "source": [
    "### Ajout de métriques robustes de popularité : Bayésienne + Wilson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03650444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Average Rating (BAR)\n",
    "global_mean = interactions['rating'].mean()\n",
    "prior_count = 10  # Nombre de \"votes\" fictifs = Paramètre bayésien\n",
    "\n",
    "# Calcul du BAR pour chaque recette\n",
    "recipe_metrics['bayes_mean'] = (\n",
    "    (recipe_metrics['avg_rating'] * recipe_metrics['n_interactions'] + global_mean * prior_count) /\n",
    "    (recipe_metrics['n_interactions'] + prior_count)\n",
    ").round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca32b63",
   "metadata": {},
   "source": [
    "- L’ajout de la moyenne bayésienne (Bayesian Average Rating) permet de corriger le biais lié au faible nombre d’interactions pour certaines recettes. Contrairement à la moyenne classique, cette approche intègre une \"prior\" globale et réduit l’impact des recettes peu notées qui pourraient apparaître artificiellement en tête du classement. \n",
    "- Cela garantit une comparaison plus robuste et équitable entre toutes les recettes, en tenant compte à la fois de la qualité perçue et de la quantité d’avis disponibles. \n",
    "- Cette statistique sera donc privilégiée pour l’analyse de la popularité afin d’éviter les effets de bord dus aux extrêmes ou aux recettes peu évaluées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056aaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilson Lower Bound (WLB) pour les notes binaires (4-5 étoiles = positif)\n",
    "def wilson_lower_bound(positives, total, confidence=0.95):\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    p = positives / total\n",
    "    z = 1.96 if confidence == 0.95 else 1.64  # z-score\n",
    "    denominator = 1 + z**2 / total\n",
    "    center = (p + z**2 / (2 * total)) / denominator\n",
    "    margin = z * np.sqrt((p * (1 - p) + z**2 / (4 * total)) / total) / denominator\n",
    "    return max(0, center - margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e990d0",
   "metadata": {},
   "source": [
    "Le score Wilson Lower Bound (WLB) est une méthode statistique permettant d’estimer une borne inférieure de confiance pour la proportion de notes positives (ici, les notes ≥ 4) d’une recette, en tenant compte du nombre total de votes et de la variabilité. \n",
    "\n",
    "Contrairement à une simple proportion, le WLB pénalise les recettes avec peu de votes et donne une estimation plus prudente de la popularité réelle. Il est particulièrement utile pour éviter que des recettes peu évaluées mais avec uniquement des avis positifs ne soient surclassées dans le classement.\n",
    "\n",
    "La formule utilisée est :\n",
    "\n",
    "$$\n",
    "WLB = \\frac{p + \\frac{z^2}{2n} - z \\sqrt{\\frac{p(1-p) + \\frac{z^2}{4n}}{n}}}{1 + \\frac{z^2}{n}}\n",
    "$$\n",
    "\n",
    "où :\n",
    "- $p$ = proportion de notes positives (≥ 4)\n",
    "- $n$ = nombre total de notes\n",
    "- $z$ = score de confiance (1.96 pour 95%)\n",
    "\n",
    "Ce score représente la borne inférieure de l’intervalle de confiance à 95% pour la proportion de notes positives. Plus le nombre de votes est élevé, plus la borne est proche de la proportion réelle. Pour les recettes peu notées, le score est fortement réduit, ce qui limite les faux positifs dans le classement de popularité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer Wilson LB\n",
    "ratings_by_recipe = interactions.groupby('recipe_id')['rating'].apply(list).to_dict()\n",
    "wilson_scores = {}\n",
    "for recipe_id, ratings in ratings_by_recipe.items():\n",
    "    ratings_clean = [r for r in ratings if pd.notna(r)]\n",
    "    if ratings_clean:\n",
    "        positives = sum(1 for r in ratings_clean if r >= 4)\n",
    "        total = len(ratings_clean)\n",
    "        wilson_scores[recipe_id] = wilson_lower_bound(positives, total)\n",
    "    else:\n",
    "        wilson_scores[recipe_id] = 0\n",
    "\n",
    "recipe_metrics['wilson_lb'] = recipe_metrics.index.map(wilson_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e4769",
   "metadata": {},
   "source": [
    "### Jointure avec Recipes + métriques temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ee481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'submitted' en datetime\n",
    "recipes['submitted'] = pd.to_datetime(recipes['submitted'])\n",
    "current_date = pd.Timestamp.now()  # Date de référence pour le calcul de l'ancienneté\n",
    "recipes['age_months'] = ((current_date - recipes['submitted']).dt.days / 30.44).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93cd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure principale\n",
    "df_analysis = recipes.merge(recipe_metrics, left_on='id', right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb851c1",
   "metadata": {},
   "source": [
    "- Choix d'une jointure 'inner' pour ne conserver que les recettes ayant au moins une interaction, ce qui correspond à notre problématique d'analyse de la popularité en fonction de l'effort culinaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques d'engagement normalisées par le temps\n",
    "df_analysis['interactions_per_month'] = df_analysis['n_interactions'] / np.maximum(1, df_analysis['age_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation pour minutes (après avoir retiré les 0 et valeurs aberrantes)\n",
    "df_analysis = df_analysis[df_analysis['minutes'].notna() & (df_analysis['minutes'] > 0)]\n",
    "df_analysis['log_minutes'] = np.log(df_analysis['minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee70d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives des métriques de popularité\n",
    "popularity_cols = ['n_interactions', 'avg_rating', 'bayes_mean', 'wilson_lb', 'interactions_per_month']\n",
    "df_analysis[popularity_cols].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5288e47",
   "metadata": {},
   "source": [
    "## 1) Analyse univariée de la popularité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefaefc",
   "metadata": {},
   "source": [
    "### 1.1) Visualisation des distributions des métriques de popularité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f884bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du nombre optimal de bins avec la règle de Freedman-Diaconis\n",
    "    # bins = (max - min) / (2*IQR/n^(1/3))\n",
    "def freedman_diaconis_bins(data):\n",
    "        data_clean = data.dropna()\n",
    "        n = len(data_clean)\n",
    "        q75, q25 = np.percentile(data_clean, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        if iqr > 0:\n",
    "            bin_width = 2 * iqr / (n ** (1/3))\n",
    "            bins = int(np.ceil((data_clean.max() - data_clean.min()) / bin_width))\n",
    "        else:\n",
    "            bins = int(np.ceil(np.sqrt(n)))  # Fallback\n",
    "            \n",
    "        # Limiter entre 10 et 100 bins\n",
    "        return max(10, min(100, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045ad01",
   "metadata": {},
   "source": [
    "Cette fonction utilitaire calcule le nombre de classes optimal pour nos histogrammes en appliquant la règle de Freedman-Diaconis :\n",
    "- on ignore les valeurs manquantes pour ne garder que les observations valides ;\n",
    "- on calcule l'écart interquartile (IQR) afin de mesurer la dispersion réelle de la distribution ;\n",
    "- on en déduit une largeur de classe puis on borne le nombre de classes entre 10 et 100 pour garder des graphiques lisibles ;\n",
    "- si les données sont trop concentrées (IQR nul), on retombe sur une règle de secours basée sur √n.\n",
    "Cela harmonise la granularité des histogrammes entre toutes les métriques de popularité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "# 1- Satisfaction: Qualité perçue via les ratings\n",
    "satisfaction_vars = ['avg_rating', 'bayes_mean', 'wilson_lb']\n",
    "\n",
    "for i, var in enumerate(satisfaction_vars):\n",
    "    optimal_bins = freedman_diaconis_bins(df_analysis[var])\n",
    "    # Histogramme\n",
    "    sns.histplot(df_analysis[var], bins = optimal_bins, kde=True, ax=axes[0, i], alpha=0.7)\n",
    "    axes[0, i].set_title(f'Distribution: {var}', fontweight='bold')\n",
    "    axes[0, i].axvline(df_analysis[var].mean(), color='red', linestyle='--', \n",
    "                       label=f'Moyenne: {df_analysis[var].mean():.3f}')\n",
    "    axes[0, i].axvline(df_analysis[var].median(), color='orange', linestyle='--',\n",
    "                       label=f'Médiane: {df_analysis[var].median():.3f}')\n",
    "    axes[0, i].legend()\n",
    "    \n",
    "    # Statistiques\n",
    "    skew = df_analysis[var].skew()\n",
    "    kurt = df_analysis[var].kurtosis()\n",
    "    axes[0, i].text(0.7, 0.9, f'Skew: {skew:.2f}\\nKurt: {kurt:.2f}', \n",
    "                    transform=axes[0, i].transAxes, bbox=dict(boxstyle=\"round\", facecolor='wheat'))\n",
    "\n",
    "# 2- Engagement: popularité via le volume/rythme des interactions\n",
    "engagement_vars = ['n_interactions', 'interactions_per_month', 'n_unique_users']\n",
    "\n",
    "for i, var in enumerate(engagement_vars):\n",
    "    optimal_bins = freedman_diaconis_bins(df_analysis[var])\n",
    "    # Vérifier si très asymétrique\n",
    "    is_skewed = df_analysis[var].skew() > 2\n",
    "    \n",
    "    # Histogramme\n",
    "    sns.histplot(df_analysis[var], bins = optimal_bins, kde=False, ax=axes[1, i], alpha=0.7)\n",
    "    \n",
    "    # Appliquer échelle log AVANT les lignes verticales et labels\n",
    "    if is_skewed:\n",
    "        axes[1, i].set_yscale('log')\n",
    "        axes[1, i].set_ylabel('Fréquence (log)')\n",
    "        axes[1, i].set_title(f'{var} (échelle log Y)', fontweight='bold')\n",
    "    else:\n",
    "        axes[1, i].set_ylabel('Fréquence')\n",
    "        axes[1, i].set_title(f'Distribution: {var}', fontweight='bold')\n",
    "    \n",
    "    # Lignes verticales APRÈS l'échelle log\n",
    "    axes[1, i].axvline(df_analysis[var].mean(), color='red', linestyle='--', \n",
    "                       label=f'Moy: {df_analysis[var].mean():.1f}')\n",
    "    axes[1, i].axvline(df_analysis[var].median(), color='orange', linestyle='--',\n",
    "                       label=f'Méd: {df_analysis[var].median():.1f}')\n",
    "    axes[1, i].legend()\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Boxplot correspondant\n",
    "    sns.boxplot(y=df_analysis[var], ax=axes[2, i])\n",
    "    if is_skewed:\n",
    "        axes[2, i].set_yscale('log')\n",
    "        axes[2, i].set_title(f'Boxplot: {var} (log Y)', fontweight='bold')\n",
    "    else:\n",
    "        axes[2, i].set_title(f'Boxplot: {var}', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad9e92",
   "metadata": {},
   "source": [
    "**Lecture des graphiques générés :**\n",
    "- Ligne 1 – `avg_rating`, `bayes_mean`, `wilson_lb` : les distributions sont concentrées autour de 4-4,5 ; les moyennes (rouge) et médianes (orange) proches montrent une satisfaction globalement élevée, avec des queues à droite pour les quelques recettes d'exception.\n",
    "- Ligne 2 – `n_interactions`, `interactions_per_month`, `n_unique_users` : les histogrammes très asymétriques justifient l'échelle logarithmique sur l'axe Y, révélant une majorité de recettes peu sollicitées et une poignée de succès massifs.\n",
    "- Ligne 3 – Boxplots associés : ils mettent en évidence la longue traîne des métriques d'engagement ; même en log, de nombreux points sont isolés, ce qui indique des comportements très hétérogènes entre recettes.\n",
    "**À retenir :**\n",
    "- Les métriques de satisfaction varient peu d'une recette à l'autre et restent proches de leurs bornes hautes.\n",
    "- Les métriques d'engagement sont dominées par quelques recettes phares ; la visualisation log nous permet de comparer sans écraser le reste de la distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb12fd",
   "metadata": {},
   "source": [
    "### 1.2) Transformations avancées des données, ajout de métriques dérivées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8de9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versions log1p des métriques d'engagement\n",
    "for var in engagement_vars:\n",
    "    df_analysis[f'log1p_{var}'] = np.log1p(df_analysis[var].clip(lower=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd5294",
   "metadata": {},
   "source": [
    "Cette boucle crée les versions `log1p` des métriques d'engagement en appliquant trois étapes :\n",
    "- on force d'abord les valeurs négatives éventuelles à 0 via `clip(lower=0)` pour rester dans le domaine du logarithme ;\n",
    "- `np.log1p` compresse ensuite la plage des valeurs tout en gardant les zéros et petits comptes lisibles ;\n",
    "- on stocke enfin chaque transformation dans une nouvelle colonne `log1p_<métrique>` pour pouvoir comparer les approches.\n",
    "Cette normalisation douce facilite les comparaisons futures et prépare les métriques à des modèles sensibles aux valeurs extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorization pour réduire l'impact des valeurs extrêmes\n",
    "def winsorize(series, lower_pct=0.05, upper_pct=0.99):\n",
    "    lower_bound = series.quantile(lower_pct)\n",
    "    upper_bound = series.quantile(upper_pct)\n",
    "    return series.clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "for var in [\"log_minutes\", \"log1p_n_interactions\", \"log1p_interactions_per_month\", \"log1p_n_unique_users\"]:\n",
    "    df_analysis[f\"{var}_w\"] = winsorize(df_analysis[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e82faf",
   "metadata": {},
   "source": [
    "La fonction `winsorize` borne chaque série en remplaçant les valeurs trop extrêmes par les percentiles 5 % et 99 % :\n",
    "- le calcul des bornes se fait sur les versions déjà transformées (log ou log1p), ce qui évite de tronquer brutalement les données brutes ;\n",
    "- le clipping conserve toutes les lignes mais limite l'influence des observations aberrantes lors des analyses graphiques ou statistiques ;\n",
    "- les colonnes suffixées `_w` serviront de référence plus robuste pour la suite de l'étude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écart à la note maximale (5) pour les métriques de satisfaction\n",
    "df_analysis[\"rating_gap\"] = 5 - df_analysis[\"avg_rating\"]\n",
    "df_analysis[\"bayes_gap\"] = 5 - df_analysis[\"bayes_mean\"]\n",
    "df_analysis[\"wilson_gap\"] = 1 - df_analysis[\"wilson_lb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9632304b",
   "metadata": {},
   "source": [
    "En calculant l'écart à la note maximale pour chaque indicateur de satisfaction :\n",
    "- `rating_gap` mesure combien de points séparent une recette de la note parfaite sur 5 ;\n",
    "- `bayes_gap` fait de même en tenant compte de la pénalisation bayésienne appliquée aux recettes peu notées ;\n",
    "- `wilson_gap` convertit le score Wilson (borne inférieure) en distance à l'optimum, ce qui homogénéise l'interprétation.\n",
    "Plus l'écart est faible, plus la recette est perçue comme satisfaisante ; ces variables serviront à repérer rapidement les recettes à améliorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e278b9",
   "metadata": {},
   "source": [
    "### 1.3) Distributions après transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "satisfaction_vars = {\n",
    "    \"avg_rating (gap)\": \"rating_gap\",\n",
    "    \"bayes_mean (gap)\": \"bayes_gap\",\n",
    "    \"wilson_lb (gap)\": \"wilson_gap\"\n",
    "}\n",
    "\n",
    "engagement_vars = {\n",
    "    \"n_interactions (log1p winsor)\": \"log1p_n_interactions_w\",\n",
    "    \"interactions_per_month (log1p winsor)\": \"log1p_interactions_per_month_w\",\n",
    "    \"n_unique_users (log1p winsor)\": \"log1p_n_unique_users_w\"\n",
    "}\n",
    "\n",
    "for col_idx, (title, col) in enumerate(satisfaction_vars.items()):\n",
    "    data = df_analysis[col].dropna()\n",
    "    bins = freedman_diaconis_bins(data)\n",
    "    sns.histplot(data, bins=bins, kde=True, ax=axes[0, col_idx], alpha=0.7)\n",
    "    axes[0, col_idx].set_title(f\"Distribution: {title}\", fontweight=\"bold\")\n",
    "    axes[0, col_idx].axvline(data.mean(), color=\"red\", linestyle=\"--\", label=f\"Moyenne: {data.mean():.3f}\")\n",
    "    axes[0, col_idx].axvline(data.median(), color=\"orange\", linestyle=\"--\", label=f\"Médiane: {data.median():.3f}\")\n",
    "    axes[0, col_idx].legend()\n",
    "    axes[0, col_idx].text(0.70, 0.9, f\"Skew: {data.skew():.2f}\\nKurt: {data.kurtosis():.2f}\",\n",
    "                          transform=axes[0, col_idx].transAxes,\n",
    "                          bbox=dict(boxstyle=\"round\", facecolor=\"wheat\"))\n",
    "\n",
    "for col_idx, (title, col) in enumerate(engagement_vars.items()):\n",
    "    data = df_analysis[col].dropna()\n",
    "    bins = freedman_diaconis_bins(data)\n",
    "    sns.histplot(data, bins=bins, kde=True, ax=axes[1, col_idx], alpha=0.7)\n",
    "    axes[1, col_idx].set_ylabel(\"Fréquence\")\n",
    "    axes[1, col_idx].set_title(f\"Distribution: {title}\", fontweight=\"bold\")\n",
    "    axes[1, col_idx].axvline(data.mean(), color=\"red\", linestyle=\"--\", label=f\"Moy: {data.mean():.2f}\")\n",
    "    axes[1, col_idx].axvline(data.median(), color=\"orange\", linestyle=\"--\", label=f\"Méd: {data.median():.2f}\")\n",
    "    axes[1, col_idx].legend()\n",
    "    axes[1, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "    sns.boxplot(y=data, ax=axes[2, col_idx])\n",
    "    axes[2, col_idx].set_title(f\"Boxplot: {title}\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ac915",
   "metadata": {},
   "source": [
    "**Effets des transformations appliquées :**\n",
    "- Les distributions des `rating_gap`, `bayes_gap` et `wilson_gap` sont très concentrées près de 0, confirmant que la satisfaction reste élevée et que seules quelques recettes s'éloignent sensiblement de la note maximale.\n",
    "- Les versions `log1p` winsorisées des métriques d'engagement deviennent beaucoup moins étalées : le cœur de distribution apparaît clairement, ce qui rend comparables les recettes aux volumes d'interactions modestes ou intermédiaires.\n",
    "- Les boxplots résiduels montrent encore des points isolés, mais ceux-ci sont désormais gérables dans des analyses corrélationnelles ou des modèles linéaires.\n",
    "\n",
    "**Conclusion pratique :**\n",
    "- Le couple `log1p` + winsorization réduit la variance et la kurtosis, stabilisant les métriques d'engagement pour les étapes analytiques qui suivent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c3c0b",
   "metadata": {},
   "source": [
    "## 2) Analyse bivariée"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mangetamain)",
   "language": "python",
   "name": "mangetamain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
